## Development of a PDF-Based Question-Answering Chatbot Using LangChain

### AIM:
To design and implement a question-answering chatbot capable of processing and extracting information from a provided PDF document using LangChain, and to evaluate its effectiveness by testing its responses to diverse queries derived from the document's content.

### PROBLEM STATEMENT:
The objective is to create a chatbot that can intelligently respond to queries based on information extracted from a PDF document. By using LangChain, the chatbot will be able to process the content of the PDF and use a language model to provide relevant answers to user queries. The effectiveness of the chatbot will be evaluated by testing it with various questions related to the document.



### DESIGN STEPS:
#### STEP 1:
Use a library like PyPDFLoader to load the PDF document. Split the content into smaller text chunks using a TextSplitter (e.g., RecursiveCharacterTextSplitter) for efficient information retrieval.

#### STEP 2:
Convert the text chunks into numerical embeddings using OpenAIEmbeddings and store them in a vector database (e.g., Chroma) to enable similarity-based search.

#### STEP 3:
Use the vector database's retriever to fetch relevant text chunks based on user queries. Set the retriever parameters (e.g., search type) for accurate results.

#### STEP 4:
Use an OpenAI language model (e.g., GPT-4 or GPT-3.5) and a retrieval chain like RetrievalQA or ConversationalRetrievalChain to combine document context with conversational responses.

#### STEP 5:
Create a conversational interface (e.g., a command-line or GUI-based system) where users can input queries, and the chatbot responds with context-aware answers based on the PDF.

### PROGRAM:
```py
import os
import openai
import sys
sys.path.append('../..')

from dotenv import load_dotenv, find_dotenv
_ = load_dotenv(find_dotenv()) # read local .env file

openai.api_key  = os.environ['OPENAI_API_KEY']

from langchain.document_loaders import PyPDFLoader
loader = PyPDFLoader("/home/jovyan/work/01_document_loading/sample-3.pdf")
pages = loader.load()

from langchain.vectorstores import Chroma
from langchain.embeddings.openai import OpenAIEmbeddings
persist_directory = 'docs/chroma/'
embedding = OpenAIEmbeddings()
vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)

from langchain.chat_models import ChatOpenAI
llm = ChatOpenAI(model_name='gpt-4', temperature=0)

from langchain.prompts import PromptTemplate
template = """Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say "thanks for asking!" at the end of the answer. 
{context}
Question: {question}
Helpful Answer:"""
QA_CHAIN_PROMPT = PromptTemplate(input_variables=["context", "question"],template=template,)


from langchain.chains import RetrievalQA
question = "What is the use of machine learning in AI"
qa_chain = RetrievalQA.from_chain_type(llm,
                                       retriever=vectordb.as_retriever(),
                                       return_source_documents=True,
                                       chain_type_kwargs={"prompt": QA_CHAIN_PROMPT})

result = qa_chain({"query": question})
print("Question: ", question)
print("Answer: ", result["result"])
```

### OUTPUT:
![image](https://github.com/user-attachments/assets/7703714a-7e3e-4d50-bb61-4d838de00506)


### RESULT:
Thus, a question-answering chatbot capable of processing and extracting information from a provided PDF document using LangChain was implemented and evaluated for its effectiveness by testing its responses to diverse queries derived from the document's content successfully.
